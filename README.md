# From SHAP to EBM: Explain you Gradient Boosting Model with Python
Code and material for the talk "From SHAP to EBM: Explain you Gradient Boosting Model with Python".

The slides can be found on [Canva](https://www.canva.com/design/DAGTcqRVq0M/udygvdcV-RdRGEPQEDKuOw/edit?utm_content=DAGTcqRVq0M&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton).

Made with ❤️ by [Emanuele Fabbiani](https://www.linkedin.com/in/emanuelefabbiani/) at [xtream](https://xtreamers.io/).

You can run the notebook for free on Google Colab.

[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/donlelef/shap-and-emb-explain-your-gradient-boosting/blob/main/notebooks/from_shap_to_ebm.ipynb)

## References
- [SHAP](https://github.com/shap/shap)
- [InterpretML](https://github.com/interpretml/interpret/)
- [Scikit-Learn documentation about explainability of tree-based models](https://scikit-learn.org/1.5/modules/permutation_importance.html#permutation-importance)
- Christoph Molnar, [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)